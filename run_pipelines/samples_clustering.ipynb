{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import knpackage.toolbox as kn\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# sys.path.insert(1, '../src')\n",
    "# import KnowEnG_graphics as gu\n",
    "sys.path.insert(1, '../../Data_Cleanup_Pipeline/src')\n",
    "import data_cleanup_toolbox as dc_tbx\n",
    "\n",
    "sys.path.insert(1, '../../Samples_Clustering_Pipeline/src')\n",
    "import sample_clustering_toolbox as sc_tbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def git_clone_Samples_Clustering(pipelines_directory):\n",
    "    \"\"\"  clone samples clustering and data cleaning if they are not installed relative to the calling notebook \"\"\"\n",
    "    working_directory = os.getcwd()\n",
    "    os.chdir(pipelines_directory)\n",
    "\n",
    "    DC_name = 'Data_Cleanup_Pipeline'\n",
    "    Data_Cleanup_Exists = False\n",
    "    SC_name = 'Samples_Clustering_Pipeline'\n",
    "    Samples_Clustering_Exists = False\n",
    "\n",
    "    dir_listing = os.listdir()\n",
    "    for d in dir_listing:\n",
    "        if os.path.isdir(d):\n",
    "            if d == DC_name:\n",
    "                Data_Cleanup_Exists = True\n",
    "            elif d == SC_name:\n",
    "                Samples_Clustering_Exists = True\n",
    "\n",
    "    if Data_Cleanup_Exists == False:\n",
    "        dc_git_string = 'git clone https://github.com/KnowEnG/Data_Cleanup_Pipeline.git'\n",
    "        os.system(dc_git_string)\n",
    "\n",
    "    if Samples_Clustering_Exists == False:\n",
    "        sc_git_string = 'git clone https://github.com/KnowEnG/Samples_Clustering_Pipeline.git'\n",
    "        os.system(sc_git_string)\n",
    "\n",
    "    os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_run_dir(target_dir, REMOVE_RESULTS=False):\n",
    "    \"\"\" setup directory for running a pipeline \"\"\"\n",
    "    if not os.path.isdir(run_dir):\n",
    "        os.mkdir(run_dir)\n",
    "\n",
    "    if os.path.isdir(results_dir) and REMOVE_RESULTS:\n",
    "        os.system('rm ' + results_dir + '/*')\n",
    "    elif not os.path.isdir(results_dir):\n",
    "        os.mkdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup(button):\n",
    "    global data_cleanup_dict\n",
    "    #     'phenotype_name_full_path':   '../../Samples_Clustering_Pipeline/data/spreadsheets/UCEC_phenotype.txt',\n",
    "    data_cleanup_dict = {\n",
    "        # 'spreadsheet_name_full_path': '../../Samples_Clustering_Pipeline/data/spreadsheets/tcga_ucec_somatic_mutation_data.df',\n",
    "        # 'gg_network_name_full_path': '../../Samples_Clustering_Pipeline/data/networks/keg_ST90_4col.edge',\n",
    "        'results_directory':          results_dir,\n",
    "        'taxonid':                    '9606',\n",
    "        'source_hint':                '',\n",
    "        'pipeline_type':              'samples_clustering_pipeline',\n",
    "        'redis_credential':\n",
    "                                {'host': 'knowredis.knowhub.org',\n",
    "                                'password': 'KnowEnG',\n",
    "                                'port': '6380'}\n",
    "    }\n",
    "\n",
    "    for w in DC_widget_list:\n",
    "        data_cleanup_dict[w.description[7:-1]] = os.path.join(target_dir,w.value)\n",
    "    # print(data_cleanup_dict)\n",
    "    \n",
    "    SUCCESS, logging = dc_tbx.run_samples_clustering_pipeline(data_cleanup_dict)\n",
    "    print(SUCCESS, logging)\n",
    "    os.listdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cd3a50716b456a9e63c724c53d83f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30486e7151564bd1ae5b99eefa38355f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad68329f34cc4234aaa554e3fdedaa63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2557021b32b246adaf84bb0346dbb270"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False ['ERROR: Setting mangle_dupe_cols=False is not supported yet']\n"
     ]
    }
   ],
   "source": [
    "git_clone_Samples_Clustering(os.path.abspath('../../'))\n",
    "\n",
    "target_dir = '../../Samples_Clustering_Pipeline/data/spreadsheets'\n",
    "\n",
    "run_dir = os.path.join(target_dir, 'run_dir')\n",
    "results_dir = os.path.join(run_dir, 'results')\n",
    "setup_run_dir(target_dir)\n",
    "\n",
    "os.system('cp ../../Samples_Clustering_Pipeline/data/networks/keg_ST90_4col.edge ' + target_dir)\n",
    "\n",
    "#                                         Get list of (docker run -v) mounted files:\n",
    "flist = os.listdir(target_dir)\n",
    "FEXT = ['.tsv', '.txt', '.df','.edge']\n",
    "my_file_list = []\n",
    "for f in flist:\n",
    "    if os.path.isfile(os.path.join(target_dir, f)):\n",
    "        noNeed, f_ext = os.path.splitext(f)\n",
    "        if f_ext in FEXT:\n",
    "            my_file_list.append(f)\n",
    "\n",
    "#                                         (docker run -v) mounted files was empty:\n",
    "if len(my_file_list) <= 0:\n",
    "    my_file_list.append('No Data')\n",
    "    \n",
    "DC_widget_list = []\n",
    "DC_widget_list.append(widgets.Dropdown(\n",
    "    options=my_file_list,\n",
    "    value=my_file_list[0],\n",
    "    description='Select spreadsheet_name_full_path:'\n",
    "))\n",
    "\n",
    "DC_widget_list.append(widgets.Dropdown(\n",
    "    options=my_file_list,\n",
    "    value=my_file_list[0],\n",
    "    description='Select phenotype_name_full_path:'\n",
    "))\n",
    "\n",
    "DC_widget_list.append(widgets.Dropdown(\n",
    "    options=my_file_list,\n",
    "    value=my_file_list[0],\n",
    "    description='Select gg_network_name_full_path:'\n",
    "))\n",
    "\n",
    "for w in DC_widget_list:\n",
    "    display(w)\n",
    "    \n",
    "data_cleanup_button = widgets.Button(\n",
    "    description='Data Cleanup',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='data cleanup button',\n",
    "    )\n",
    "data_cleanup_button.on_click(data_cleanup)\n",
    "display(data_cleanup_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_cluster_dict = {\n",
    "#             'method': 'cc_net_nmf',\n",
    "#             'spreadsheet_name_full_path': '../test/run_dir/results/tcga_ucec_somatic_mutation_data_ETL.tsv',\n",
    "#             'phenotype_name_full_path':   '../test/run_dir/results/UCEC_phenotype_ETL.tsv',\n",
    "#             'threshold': '10',\n",
    "#             'gg_network_name_full_path':  '../data/networks/keg_ST90_4col.edge',\n",
    "#             'results_directory':          '../../user_data/run_dir/results',\n",
    "#             'tmp_directory':               '../../user_data/run_dir',\n",
    "#             'rwr_max_iterations':         '100',\n",
    "#             'rwr_convergence_tolerence':  '1.0e-4',\n",
    "#             'rwr_restart_probability':    '0.7',\n",
    "#             'rows_sampling_fraction':     '0.8',\n",
    "#             'cols_sampling_fraction':     '0.8',\n",
    "#             'number_of_bootstraps':       '4',\n",
    "#             'number_of_clusters':         '3',\n",
    "#             'nmf_conv_check_freq':        '50',\n",
    "#             'nmf_max_invariance':         '200',\n",
    "#             'nmf_max_iterations':         '10000',\n",
    "#             'nmf_penalty_parameter':      '1400',\n",
    "#             'top_number_of_genes':        '100',\n",
    "#             'processing_method':          'parallel',\n",
    "#             'parallelism':                '4'\n",
    "#         }\n",
    "\n",
    "method_list = ['nmf', 'cc_nmf', 'net_nmf', 'cc_net_nmf']\n",
    "threshold_range = {'low':2, 'high':100, 'tip':'categorical vs numerical cutoff threshold'}\n",
    "rwr_max_iterations_range = {'low':2, 'high':1000, 'tip':'random walk no convergence iteration limit'}\n",
    "rwr_convergence_tolerence_range = {'low':1.0e-16, 'high':1000, 'tip':'minimum norm difference'}\n",
    "rwr_restart_probability_range = {'low':0, 'high':1, 'tip': 'Vn+1 = alpha * N * Vn + (1-alpha) * Vo'}\n",
    "rows_sampling_fraction_range = {'low':0, 'high':1, 'tip': 'bootstrap sampling fraction of spreadsheet rows'}\n",
    "cols_sampling_fraction_range = {'low':0, 'high':1, 'tip': 'bootstrap sampling fraction of spreadsheet columns'}\n",
    "number_of_bootstraps_range = {'low':1, 'high':2000, 'tip': 'more bootstrap samples == more run time'}\n",
    "number_of_clusters_range = {'low':2, 'high':12, 'tip': 'more clusters == more run time'}\n",
    "\n",
    "# optional parameters\n",
    "nmf_conv_check_freq_range = {'low':1, 'high':1000, 'tip': 'more frequent checks == more run time'}\n",
    "# nmf_max_invariance_range = \n",
    "\n",
    "# available clusters: AWS, CS Cluster\n",
    "# available methods: serial, parallel, distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_clustering(button):\n",
    "    spreadsheet_name_post_clean = os.path.splitext(DC_widget_list[0].value)[0] + '_ETL.tsv'\n",
    "    phenotype_name_post_clean = os.path.splitext(DC_widget_list[1].value)[0] + '_ETL.tsv'\n",
    "    spreadsheet_name_post_clean = os.path.join(results_dir, spreadsheet_name_post_clean)\n",
    "    phenotype_name_post_clean = os.path.join(results_dir, phenotype_name_post_clean)\n",
    "    try:\n",
    "        samples_cluster_dict = {\n",
    "                 'spreadsheet_name_full_path': spreadsheet_name_post_clean,\n",
    "                 'phenotype_name_full_path':   phenotype_name_post_clean,\n",
    "                 'gg_network_name_full_path':  data_cleanup_dict['gg_network_name_full_path'],\n",
    "                 'results_directory':          results_dir,\n",
    "                 'run_directory':              run_dir,\n",
    "        }\n",
    "\n",
    "        for w in SC_widget_list:\n",
    "            if not isinstance(w,widgets.Label):\n",
    "                samples_cluster_dict[w.description[7:-1]] = w.value\n",
    "\n",
    "        if samples_cluster_dict['method'] == 'cc_net_nmf':\n",
    "            sc_tbx.run_cc_net_nmf(samples_cluster_dict)\n",
    "    except NameError:\n",
    "        print('You should run Data Cleanup Pipeline first! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b33762d38146ec872a2a1fb948aa9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e58d19ceb14fc187c3dcce1842fa05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb3a828c61b4ec38ec36280fbd5022f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ea912652394ec7bec5f454f9c3d1b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3025ac6151545879e754cfe3a1c434b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2990412fac784ffabf8303091c0295cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38a74ce151249eea90a4b6f5c96c177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564b5b83ef324b3e8984c1b830e2b7ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6d124d2e484fe09dd33e7bb4208e6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db48cd8abc045b4897b9ae2ed7042df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d72335b05c74fefbfffbf837f774f4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7732bf6008b14146b9fa6f1d6f3b640b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b99cbfcf5a45b6a2f9655b5fdd1383"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5b052615014ec993c66c862be16229"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error during reading input file ../../Samples_Clustering_Pipeline/data/spreadsheets/run_dir/results/tcga_ucec_somatic_mutation_data_ETL.tsv: <class 'FileNotFoundError'>\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../../Samples_Clustering_Pipeline/data/spreadsheets/run_dir/results/tcga_ucec_somatic_mutation_data_ETL.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-eb46e5422661>\u001b[0m in \u001b[0;36msamples_clustering\u001b[0;34m(button)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msamples_cluster_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cc_net_nmf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0msc_tbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cc_net_nmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_cluster_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You should run Data Cleanup Pipeline first! '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xikun/KnowEng/Samples_Clustering_Pipeline/src/sample_clustering_toolbox.py\u001b[0m in \u001b[0;36mrun_cc_net_nmf\u001b[0;34m(run_parameters)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mlap_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlap_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mform_network_laplacian_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mspreadsheet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spreadsheet_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_name_full_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mspreadsheet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_spreadsheet_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_gene_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mspreadsheet_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspreadsheet_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xikun/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/knpackage/toolbox.py\u001b[0m in \u001b[0;36mget_spreadsheet_df\u001b[0;34m(spreadsheet_name_full_path)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mspreadsheet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_name_full_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         print(\"Unexpected error during reading input file {}: {}\".format(spreadsheet_name_full_path,\n",
      "\u001b[0;32m/home/xikun/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xikun/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xikun/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xikun/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xikun/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../../Samples_Clustering_Pipeline/data/spreadsheets/run_dir/results/tcga_ucec_somatic_mutation_data_ETL.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "SC_widget_list = []\n",
    "SC_widget_list.append(widgets.Dropdown(\n",
    "    options=method_list,\n",
    "    value='cc_net_nmf',\n",
    "    description='Select method:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.IntSlider(\n",
    "    min=2, \n",
    "    max=100,  \n",
    "    value=10, \n",
    "    description='Select threshold:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.IntSlider(\n",
    "    min=2, \n",
    "    max=1000, \n",
    "    value=100, \n",
    "    description='Select rwr_max_iterations:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.BoundedFloatText(\n",
    "    min=1.0e-16, \n",
    "    max=1000,  \n",
    "    value=1e-4, \n",
    "    description='Select rwr_convergence_tolerence:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.FloatSlider(\n",
    "    min=0, \n",
    "    max=1,  \n",
    "    value=0.7, \n",
    "    description='Select rwr_restart_probability:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.FloatSlider(\n",
    "    min=0, \n",
    "    max=1,  \n",
    "    value=0.8, \n",
    "    description='Select rows_sampling_fraction:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.FloatSlider(\n",
    "    min=0, \n",
    "    max=1, \n",
    "    value=0.8, \n",
    "    description='Select cols_sampling_fraction:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.IntSlider(\n",
    "    min=1, \n",
    "    max=2000, \n",
    "    value=4, \n",
    "    description='Select number_of_bootstraps:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.IntSlider(\n",
    "    min=2, \n",
    "    max=12,  \n",
    "    value=3, \n",
    "    description='Select number_of_clusters:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.Label(\n",
    "    value='Optional Parameters: '\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.IntSlider(\n",
    "    min=1, \n",
    "    max=1000,\n",
    "    value=50, \n",
    "    description='Select nmf_conv_check_freq:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.Dropdown(\n",
    "    options=['serial', 'parallel', 'distribute'],\n",
    "    value='parallel',\n",
    "    description='Select processing_method:'\n",
    "))\n",
    "\n",
    "SC_widget_list.append(widgets.IntSlider(\n",
    "    min=1, \n",
    "    max=4,  \n",
    "    value=4, \n",
    "    description='Select parallelism:'\n",
    "))\n",
    "\n",
    "for w in SC_widget_list:\n",
    "    display(w)\n",
    "        \n",
    "samples_clustering_button = widgets.Button(\n",
    "    description='Samples Clustering',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='samples clustering button',\n",
    "    )\n",
    "samples_clustering_button.on_click(samples_clustering)\n",
    "display(samples_clustering_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
