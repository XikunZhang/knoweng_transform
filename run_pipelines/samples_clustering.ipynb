{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "# <style>\n",
    "# div.input {\n",
    "#     display:none;\n",
    "# }\n",
    "# div.output_stderr{\n",
    "#     display:none\n",
    "# }\n",
    "# </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import knpackage.toolbox as kn\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def git_clone_Samples_Clustering(pipelines_directory):\n",
    "    \"\"\"  clone samples clustering and data cleaning if they are not installed relative to the calling notebook \"\"\"\n",
    "    working_directory = os.getcwd()\n",
    "    os.chdir(pipelines_directory)\n",
    "\n",
    "    DC_name = 'Data_Cleanup_Pipeline'\n",
    "    Data_Cleanup_Exists = False\n",
    "    SC_name = 'Samples_Clustering_Pipeline'\n",
    "    Samples_Clustering_Exists = False\n",
    "\n",
    "    dir_listing = os.listdir()\n",
    "    for d in dir_listing:\n",
    "        if os.path.isdir(d):\n",
    "            if d == DC_name:\n",
    "                Data_Cleanup_Exists = True\n",
    "            elif d == SC_name:\n",
    "                Samples_Clustering_Exists = True\n",
    "\n",
    "    if Data_Cleanup_Exists == False:\n",
    "        dc_git_string = 'git clone https://github.com/KnowEnG/Data_Cleanup_Pipeline.git'\n",
    "        os.system(dc_git_string)\n",
    "\n",
    "    if Samples_Clustering_Exists == False:\n",
    "        sc_git_string = 'git clone https://github.com/KnowEnG/Samples_Clustering_Pipeline.git'\n",
    "        os.system(sc_git_string)\n",
    "\n",
    "    os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_clone_Samples_Clustering(os.path.abspath('../../'))\n",
    "\n",
    "# sys.path.insert(1, '../src')\n",
    "# import KnowEnG_graphics as gu\n",
    "sys.path.insert(1, '../../Data_Cleanup_Pipeline/src')\n",
    "import data_cleanup_toolbox as dc_tbx\n",
    "\n",
    "sys.path.insert(1, '../../Samples_Clustering_Pipeline/src')\n",
    "import sample_clustering_toolbox as sc_tbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_run_dir(run_dir, results_dir, REMOVE_RESULTS=False):\n",
    "    \"\"\" setup directory for running a pipeline \"\"\"\n",
    "    if not os.path.isdir(run_dir):\n",
    "        os.mkdir(run_dir)\n",
    "\n",
    "    if os.path.isdir(results_dir) and REMOVE_RESULTS:\n",
    "        os.system('rm ' + results_dir + '/*')\n",
    "    elif not os.path.isdir(results_dir):\n",
    "        os.mkdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    target_dir = '../../Samples_Clustering_Pipeline/data'\n",
    "    run_dir = os.path.join(target_dir, 'run_dir')\n",
    "    results_dir = os.path.join(run_dir, 'results')\n",
    "    setup_run_dir(run_dir, results_dir)\n",
    "\n",
    "    working_directory = os.getcwd()\n",
    "    os.chdir(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d98d0d3954dbe9acb6dbfd45bc07e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab27dceafc7645999cf6951af930cb9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d96dfd25854478bb2b237bb08bc9fc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef71d8cf0fb44440bc06358ecbadb9ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9028e036064c8383cfca63ec56e345"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336d77736d8346b9abfd150dfb521bff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1870a45c9fa041bdb083e83a54a51ee8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118e29ac57834dea811c3b354bbd826d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca507a71b58a4efca78dc9fd26d781aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44c123938d048aebcfc1ff9112d5f46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a917c01fccf2402789697374eaceb336"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d70258bb244c49ba8b6bab20a8c4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca1176fcdfc4367913f61df3b60647b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bbc1c2bc0b49f2a38e30aa575a8744"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b614aff960c24366bb62ac2188be942e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a9c2a4eaa24adf85b7bfebb8886706"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4781fc6a45484266a0a43da8ab8bd347"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78019268c8c042ccb32c3a57861d7773"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97fa39b512b4c76a4faf6d6c0f956fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f223779e1d2c46c596b000330007425f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleanup completed successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#                                         Get list of (docker run -v) mounted files:\n",
    "run_file_directory = '../../Samples_Clustering_Pipeline/data/run_files'\n",
    "run_dir_flist = os.listdir(run_file_directory)\n",
    "FEXT = '.yml'\n",
    "run_file_list = []\n",
    "for f in run_dir_flist:\n",
    "    if os.path.isfile(os.path.join(run_file_directory, f)):\n",
    "        noNeed, f_ext = os.path.splitext(f)\n",
    "        if f_ext == FEXT:\n",
    "            run_file_list.append(f)\n",
    "\n",
    "#                                         (docker run -v) mounted files was empty:\n",
    "if len(run_file_list) <= 0:\n",
    "    run_file_list.append('No Data')\n",
    "    \n",
    "run_file_dropdown = widgets.Dropdown(\n",
    "    description='Select run file: ', \n",
    "    options=run_file_list, \n",
    "    value=run_file_list[0]\n",
    "    )\n",
    "run_file_submit_button = widgets.Button(\n",
    "    description='Use this run file', \n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='run file submit button',\n",
    "    )\n",
    "display(run_file_dropdown, run_file_submit_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def run_two_pipelines(button):\n",
    "    yaml_file_full_path = os.path.join(run_file_directory, run_file_dropdown.value)\n",
    "\n",
    "    global run_parameters\n",
    "    with open(yaml_file_full_path, 'r') as infile:\n",
    "        run_parameters = yaml.load(infile)\n",
    "    os.system('cp ' + run_parameters['gg_network_name_full_path'] + ' ' + target_dir)\n",
    "    os.system('cp ' + run_parameters['spreadsheet_name_full_path'] + ' ' + target_dir)\n",
    "    os.system('cp ' + run_parameters['phenotype_name_full_path'] + ' ' + target_dir)\n",
    "\n",
    "    os.chdir(working_directory)\n",
    "\n",
    "    #                                         Get list of (docker run -v) mounted files:\n",
    "    flist = os.listdir(target_dir)\n",
    "    FEXT = ['.tsv', '.txt', '.df','.edge']\n",
    "    my_file_list = []\n",
    "    for f in flist:\n",
    "        if os.path.isfile(os.path.join(target_dir, f)):\n",
    "            noNeed, f_ext = os.path.splitext(f)\n",
    "            if f_ext in FEXT:\n",
    "                my_file_list.append(f)\n",
    "\n",
    "    #                                         (docker run -v) mounted files was empty:\n",
    "    if len(my_file_list) <= 0:\n",
    "        my_file_list.append('No Data')\n",
    "\n",
    "    global DC_widget_list\n",
    "    DC_widget_list = []\n",
    "    DC_widget_list.append(widgets.Dropdown(\n",
    "        options=my_file_list,\n",
    "        value=os.path.basename(run_parameters['spreadsheet_name_full_path']),\n",
    "        description='Select spreadsheet_name_full_path:'\n",
    "    ))\n",
    "\n",
    "    DC_widget_list.append(widgets.Dropdown(\n",
    "        options=my_file_list,\n",
    "        value=os.path.basename(run_parameters['phenotype_name_full_path']),\n",
    "        description='Select phenotype_name_full_path:'\n",
    "    ))\n",
    "\n",
    "    DC_widget_list.append(widgets.Dropdown(\n",
    "        options=my_file_list,\n",
    "        value=os.path.basename(run_parameters['gg_network_name_full_path']),\n",
    "        description='Select gg_network_name_full_path:'\n",
    "    ))\n",
    "\n",
    "    for w in DC_widget_list:\n",
    "         display(w)\n",
    "\n",
    "    data_cleanup_button = widgets.Button(\n",
    "        description='Data Cleanup',\n",
    "        disabled=False,\n",
    "        button_style='',\n",
    "        tooltip='data cleanup button',\n",
    "        )\n",
    "    data_cleanup_button.on_click(data_cleanup)\n",
    "    display(data_cleanup_button)\n",
    "\n",
    "    # samples_cluster_dict = {\n",
    "    #             'method': 'cc_net_nmf',\n",
    "    #             'spreadsheet_name_full_path': '../test/run_dir/results/tcga_ucec_somatic_mutation_data_ETL.tsv',\n",
    "    #             'phenotype_name_full_path':   '../test/run_dir/results/UCEC_phenotype_ETL.tsv',\n",
    "    #             'threshold': '10',\n",
    "    #             'gg_network_name_full_path':  '../data/networks/keg_ST90_4col.edge',\n",
    "    #             'results_directory':          '../../user_data/run_dir/results',\n",
    "    #             'run_directory':               '../../user_data/run_dir',\n",
    "    #             'rwr_max_iterations':         '100',\n",
    "    #             'rwr_convergence_tolerence':  '1.0e-4',\n",
    "    #             'rwr_restart_probability':    '0.7',\n",
    "    #             'rows_sampling_fraction':     '0.8',\n",
    "    #             'cols_sampling_fraction':     '0.8',\n",
    "    #             'number_of_bootstraps':       '4',\n",
    "    #             'number_of_clusters':         '3',\n",
    "    #             'nmf_conv_check_freq':        '50',\n",
    "    #             'nmf_max_invariance':         '200',\n",
    "    #             'nmf_max_iterations':         '10000',\n",
    "    #             'nmf_penalty_parameter':      '1400',\n",
    "    #             'top_number_of_genes':        '100',\n",
    "    #             'processing_method':          'parallel',\n",
    "    #             'parallelism':                '4'\n",
    "    #         }\n",
    "\n",
    "    method_list = ['nmf', 'cc_nmf', 'net_nmf', 'cc_net_nmf']\n",
    "    threshold_range = {'low':2, 'high':100, 'tip':'categorical vs numerical cutoff threshold'}\n",
    "    rwr_max_iterations_range = {'low':2, 'high':1000, 'tip':'random walk no convergence iteration limit'}\n",
    "    rwr_convergence_tolerence_range = {'low':1.0e-16, 'high':1000, 'tip':'minimum norm difference'}\n",
    "    rwr_restart_probability_range = {'low':0, 'high':1, 'tip': 'Vn+1 = alpha * N * Vn + (1-alpha) * Vo'}\n",
    "    rows_sampling_fraction_range = {'low':0, 'high':1, 'tip': 'bootstrap sampling fraction of spreadsheet rows'}\n",
    "    cols_sampling_fraction_range = {'low':0, 'high':1, 'tip': 'bootstrap sampling fraction of spreadsheet columns'}\n",
    "    number_of_bootstraps_range = {'low':1, 'high':2000, 'tip': 'more bootstrap samples == more run time'}\n",
    "    number_of_clusters_range = {'low':2, 'high':12, 'tip': 'more clusters == more run time'}\n",
    "\n",
    "    # optional parameters\n",
    "    nmf_conv_check_freq_range = {'low':1, 'high':1000, 'tip': 'more frequent checks == more run time'}\n",
    "    # nmf_max_invariance_range = \n",
    "\n",
    "    # available clusters: AWS, CS Cluster\n",
    "    # available methods: serial, parallel, distribute\n",
    "\n",
    "    global SC_widget_list\n",
    "    SC_widget_list = []\n",
    "    SC_widget_list.append(widgets.Dropdown(\n",
    "        options=method_list,\n",
    "        value=run_parameters['method'],\n",
    "        description='Select method:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.IntSlider(\n",
    "        min=2, \n",
    "        max=100,  \n",
    "        value=run_parameters['threshold'], \n",
    "        description='Select threshold:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.IntSlider(\n",
    "        min=2, \n",
    "        max=1000, \n",
    "        value=run_parameters['rwr_max_iterations'], \n",
    "        description='Select rwr_max_iterations:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.BoundedFloatText(\n",
    "        min=1.0e-16, \n",
    "        max=1000,  \n",
    "        value=run_parameters['rwr_convergence_tolerence'], \n",
    "        description='Select rwr_convergence_tolerence:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.FloatSlider(\n",
    "        min=0, \n",
    "        max=1,  \n",
    "        value=run_parameters['rwr_restart_probability'], \n",
    "        description='Select rwr_restart_probability:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.FloatSlider(\n",
    "        min=0, \n",
    "        max=1,  \n",
    "        value=run_parameters['rows_sampling_fraction'], \n",
    "        description='Select rows_sampling_fraction:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.FloatSlider(\n",
    "        min=0, \n",
    "        max=1, \n",
    "        value=run_parameters['cols_sampling_fraction'], \n",
    "        description='Select cols_sampling_fraction:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.IntSlider(\n",
    "        min=1, \n",
    "        max=2000, \n",
    "        value=run_parameters['number_of_bootstraps'], \n",
    "        description='Select number_of_bootstraps:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.IntSlider(\n",
    "        min=2, \n",
    "        max=12,  \n",
    "        value=run_parameters['number_of_clusters'], \n",
    "        description='Select number_of_clusters:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.Label(\n",
    "        value='Optional Parameters: '\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.IntSlider(\n",
    "        min=1, \n",
    "        max=1000,\n",
    "        value=run_parameters['nmf_conv_check_freq'] if 'nmf_conv_check_freq' in run_parameters else 50, \n",
    "        description='Select nmf_conv_check_freq:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.Dropdown(\n",
    "        options=['serial', 'parallel', 'distribute'],\n",
    "        value=run_parameters['processing_method'] if 'processing_method' in run_parameters else 'parallel',\n",
    "        description='Select processing_method:'\n",
    "    ))\n",
    "\n",
    "    SC_widget_list.append(widgets.IntSlider(\n",
    "        min=1, \n",
    "        max=4,  \n",
    "        value=run_parameters['parallelism'] if 'parallelism' in run_parameters else 4, \n",
    "        description='Select parallelism:'\n",
    "    ))\n",
    "\n",
    "    for w in SC_widget_list:\n",
    "        display(w)\n",
    "\n",
    "    samples_clustering_button = widgets.Button(\n",
    "        description='Samples Clustering',\n",
    "        disabled=False,\n",
    "        button_style='',\n",
    "        tooltip='samples clustering button',\n",
    "        )\n",
    "    samples_clustering_button.on_click(samples_clustering)\n",
    "    display(samples_clustering_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_file_submit_button.on_click(run_two_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup(button):\n",
    "    \n",
    "    global run_parameters\n",
    "    for w in DC_widget_list:\n",
    "        run_parameters[w.description[7:-1]] = os.path.join(target_dir,w.value)\n",
    "    \n",
    "    data_cleanup_dict = {\n",
    "        # 'spreadsheet_name_full_path': '../../Samples_Clustering_Pipeline/data/spreadsheets/tcga_ucec_somatic_mutation_data.df',\n",
    "        # 'gg_network_name_full_path': '../../Samples_Clustering_Pipeline/data/networks/keg_ST90_4col.edge',\n",
    "        'results_directory':          results_dir,\n",
    "        'taxonid':                    '9606',\n",
    "        'source_hint':                '',\n",
    "        'pipeline_type':              'samples_clustering_pipeline',\n",
    "        'redis_credential':\n",
    "                                {'host': 'knowredis.knowhub.org',\n",
    "                                'password': 'KnowEnG',\n",
    "                                'port': '6380'}\n",
    "    }\n",
    "    \n",
    "    run_parameters = {**run_parameters, **data_cleanup_dict}\n",
    "    \n",
    "    SUCCESS, logging = dc_tbx.run_samples_clustering_pipeline(run_parameters)\n",
    "    if SUCCESS == True:\n",
    "        print('Data Cleanup completed successfully')\n",
    "    else:\n",
    "        print('Data Cleanup Failed - message log:\\n')\n",
    "        for k in logging:\n",
    "            print(k)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_clustering(button):\n",
    "    spreadsheet_name_post_clean = os.path.splitext(DC_widget_list[0].value)[0] + '_ETL.tsv'\n",
    "    phenotype_name_post_clean = os.path.splitext(DC_widget_list[1].value)[0] + '_ETL.tsv'\n",
    "    spreadsheet_name_post_clean = os.path.join(results_dir, spreadsheet_name_post_clean)\n",
    "    phenotype_name_post_clean = os.path.join(results_dir, phenotype_name_post_clean)\n",
    "    try:\n",
    "        run_parameters['spreadsheet_name_full_path'] = spreadsheet_name_post_clean\n",
    "        run_parameters['phenotype_name_full_path'] = phenotype_name_post_clean\n",
    "        run_parameters['run_directory'] = run_dir\n",
    "        run_parameters['results_directory'] = results_dir\n",
    "\n",
    "        for w in SC_widget_list:\n",
    "            if not isinstance(w,widgets.Label):\n",
    "                run_parameters[w.description[7:-1]] = w.value\n",
    "\n",
    "        if run_parameters['method'] == 'cc_net_nmf':\n",
    "            sc_tbx.run_cc_net_nmf(run_parameters)\n",
    "    except NameError:\n",
    "        print('You should run Data Cleanup Pipeline first! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
