{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import knpackage.toolbox as kn\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# sys.path.insert(1, '../src')\n",
    "# import KnowEnG_graphics as gu\n",
    "sys.path.insert(1, '../../Data_Cleanup_Pipeline/src')\n",
    "import data_cleanup_toolbox as dc_tbx\n",
    "\n",
    "sys.path.insert(1, '../../Samples_Clustering_Pipeline/src')\n",
    "import sample_clustering_toolbox as sc_tbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def git_clone_Samples_Clustering(pipelines_directory):\n",
    "    \"\"\"  clone samples clustering and data cleaning if they are not installed relative to the calling notebook \"\"\"\n",
    "    working_directory = os.getcwd()\n",
    "    os.chdir(pipelines_directory)\n",
    "\n",
    "    DC_name = 'Data_Cleanup_Pipeline'\n",
    "    Data_Cleanup_Exists = False\n",
    "    SC_name = 'Samples_Clustering_Pipeline'\n",
    "    Samples_Clustering_Exists = False\n",
    "\n",
    "    dir_listing = os.listdir()\n",
    "    for d in dir_listing:\n",
    "        if os.path.isdir(d):\n",
    "            if d == DC_name:\n",
    "                Data_Cleanup_Exists = True\n",
    "            elif d == SC_name:\n",
    "                Samples_Clustering_Exists = True\n",
    "\n",
    "    if Data_Cleanup_Exists == False:\n",
    "        dc_git_string = 'git clone https://github.com/KnowEnG/Data_Cleanup_Pipeline.git'\n",
    "        os.system(dc_git_string)\n",
    "\n",
    "    if Samples_Clustering_Exists == False:\n",
    "        sc_git_string = 'git clone https://github.com/KnowEnG/Samples_Clustering_Pipeline.git'\n",
    "        os.system(sc_git_string)\n",
    "\n",
    "    os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_run_dir_run_file(target_dir, REMOVE_RESULTS=False):\n",
    "    \"\"\" setup directory for running a pipeline \"\"\"\n",
    "    if not os.path.isdir(os.path.join(target_dir, 'run_dir')):\n",
    "        os.mkdir(os.path.join(target_dir, 'run_dir'))\n",
    "\n",
    "    if os.path.isdir(os.path.join(target_dir, 'run_dir/results')) and REMOVE_RESULTS:\n",
    "        os.system('rm ' + os.path.join(target_dir, 'run_dir/results') + '/*')\n",
    "    elif not os.path.isdir(os.path.join(target_dir, 'run_dir/results')):\n",
    "        os.mkdir(os.path.join(target_dir, 'run_dir/results'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_cleanup(button):\n",
    "    #     'phenotype_name_full_path':   '../../Samples_Clustering_Pipeline/data/spreadsheets/UCEC_phenotype.txt',\n",
    "    data_cleanup_dict = {\n",
    "        # 'spreadsheet_name_full_path': '../../Samples_Clustering_Pipeline/data/spreadsheets/tcga_ucec_somatic_mutation_data.df',\n",
    "        # 'gg_network_name_full_path': '../../Samples_Clustering_Pipeline/data/networks/keg_ST90_4col.edge',\n",
    "        'results_directory':          os.path.join(target_dir, 'run_dir/results'),\n",
    "        'taxonid':                    '9606',\n",
    "        'source_hint':                '',\n",
    "        'pipeline_type':              'samples_clustering_pipeline',\n",
    "        'redis_credential':\n",
    "                                {'host': 'knowredis.knowhub.org',\n",
    "                                'password': 'KnowEnG',\n",
    "                                'port': '6380'}\n",
    "    }\n",
    "\n",
    "    data_cleanup_dict['spreadsheet_name_full_path'] = os.path.join(target_dir,DC_widget_list[0].value)\n",
    "    data_cleanup_dict['phenotype_name_full_path'] = os.path.join(target_dir,DC_widget_list[1].value)\n",
    "    SUCCESS, logging = dc_tbx.run_samples_clustering_pipeline(data_cleanup_dict)\n",
    "    print(SUCCESS, logging)\n",
    "    os.listdir(os.path.join(target_dir, 'run_dir/results'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47c934135f04dd3a848347f0fee46e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87065f4a409a4dd2b0b6a4dfb9d6e520"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4798337678c1400e939e6602eea12bf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False ['ERROR: Setting mangle_dupe_cols=False is not supported yet']\n"
     ]
    }
   ],
   "source": [
    "git_clone_Samples_Clustering(os.path.abspath('../../'))\n",
    "\n",
    "target_dir = '../../Samples_Clustering_Pipeline/data/spreadsheets'\n",
    "\n",
    "setup_run_dir_run_file(target_dir)\n",
    "\n",
    "#                                         Get list of (docker run -v) mounted files:\n",
    "flist = os.listdir(target_dir)\n",
    "FEXT = ['.tsv', '.txt', '.df','.edge']\n",
    "my_file_list = []\n",
    "for f in flist:\n",
    "    if os.path.isfile(os.path.join(target_dir, f)):\n",
    "        noNeed, f_ext = os.path.splitext(f)\n",
    "        if f_ext in FEXT:\n",
    "            my_file_list.append(f)\n",
    "\n",
    "#                                         (docker run -v) mounted files was empty:\n",
    "if len(my_file_list) <= 0:\n",
    "    my_file_list.append('No Data')\n",
    "    \n",
    "DC_widget_list = []\n",
    "DC_widget_list.append(widgets.Dropdown(\n",
    "    options=my_file_list,\n",
    "    value=my_file_list[0],\n",
    "    description='Select spreadsheet_name_full_path:'\n",
    "))\n",
    "\n",
    "DC_widget_list.append(widgets.Dropdown(\n",
    "    options=my_file_list,\n",
    "    value=my_file_list[0],\n",
    "    description='Select phenotype_name_full_path:'\n",
    "))\n",
    "\n",
    "for w in DC_widget_list:\n",
    "    display(w)\n",
    "    \n",
    "data_cleanup_button = widgets.Button(\n",
    "    description='Data Cleanup',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='data cleanup button',\n",
    "    )\n",
    "data_cleanup_button.on_click(data_cleanup)\n",
    "display(data_cleanup_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-306090a80be8>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-306090a80be8>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    nmf_max_invariance_range =\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# samples_cluster_dict = {\n",
    "#             'method': 'cc_net_nmf',\n",
    "#             'spreadsheet_name_full_path': '../test/run_dir/results/tcga_ucec_somatic_mutation_data_ETL.tsv',\n",
    "#             'phenotype_name_full_path':   '../test/run_dir/results/UCEC_phenotype_ETL.tsv',\n",
    "#             'threshold': '10',\n",
    "#             'gg_network_name_full_path':  '../data/networks/keg_ST90_4col.edge',\n",
    "#             'results_directory':          '../../user_data/run_dir/results',\n",
    "#             'tmp_directory':               '../../user_data/run_dir',\n",
    "#             'rwr_max_iterations':         '100',\n",
    "#             'rwr_convergence_tolerence':  '1.0e-4',\n",
    "#             'rwr_restart_probability':    '0.7',\n",
    "#             'rows_sampling_fraction':     '0.8',\n",
    "#             'cols_sampling_fraction':     '0.8',\n",
    "#             'number_of_bootstraps':       '4',\n",
    "#             'number_of_clusters':         '3',\n",
    "#             'nmf_conv_check_freq':        '50',\n",
    "#             'nmf_max_invariance':         '200',\n",
    "#             'nmf_max_iterations':         '10000',\n",
    "#             'nmf_penalty_parameter':      '1400',\n",
    "#             'top_number_of_genes':        '100',\n",
    "#             'processing_method':          'parallel',\n",
    "#             'parallelism':                '4'\n",
    "#         }\n",
    "\n",
    "method_list = ['nmf', 'cc_nmf', 'net_nmf', 'cc_net_nmf']\n",
    "threshold_range = {'low':2, 'high':100, 'tip':'categorical vs numerical cutoff threshold'}\n",
    "rwr_max_iterations_range = {'low':2, 'high':1000, 'tip':'random walk no convergence iteration limit'}\n",
    "rwr_convergence_tolerence_range = {'low':1.0e-16, 'high':1000, 'tip':'minimum norm difference'}\n",
    "rwr_restart_probability_range = {'low':0, 'high':1, 'tip': 'Vn+1 = alpha * N * Vn + (1-alpha) * Vo'}\n",
    "rows_sampling_fraction_range = {'low':0, 'high':1, 'tip': 'bootstrap sampling fraction of spreadsheet rows'}\n",
    "cols_sampling_fraction_range = {'low':0, 'high':1, 'tip': 'bootstrap sampling fraction of spreadsheet columns'}\n",
    "number_of_bootstraps_range = {'low':1, 'high':2000, 'tip': 'more bootstrap samples == more run time'}\n",
    "number_of_clusters_range = {'low':2, 'high':12, 'tip': 'more clusters == more run time'}\n",
    "# optional parameters\n",
    "nmf_conv_check_freq_range = {'low':1, 'high':1000, 'tip': 'more frequent checks == more run time'}\n",
    "nmf_max_invariance_range = \n",
    "# available clusters: AWS, CS Cluster\n",
    "# available methods: serial, parallel, distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SC_widget_list = []\n",
    "SC_widget_list[0] = widgets.Dropdown(\n",
    "    options=method_list,\n",
    "    value=method_list[0],\n",
    "    description='Select method:'\n",
    ")\n",
    "\n",
    "SC_widget_list[1] = widgets.IntSlider(\n",
    "    min=2, \n",
    "    max=100,  \n",
    "    description='Select threshold:'\n",
    ")\n",
    "\n",
    "SC_widget_list[1] = widgets.IntSlider(\n",
    "    min=2, \n",
    "    max=100,  \n",
    "    description='Select method:'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spreadsheet_name_post_clean = os.pathsplitext(DC_widget_list[0].value) + '_ETL' \\\n",
    "        + os.pathsplitext(DC_widget_list[0].value)\n",
    "phenotype_name_post_clean = os.pathsplitext(DC_widget_list[1].value) + '_ETL' \\\n",
    "        + os.pathsplitext(DC_widget_list[1].value)\n",
    "samples_cluster_dict = {\n",
    "        'spreadsheet_name_full_path': os.path.join(data_cleanup_dict['results_directory'], spreadsheet_name_post_clean), \n",
    "        'phenotype_name_full_path': os.path.join(data_cleanup_dict['results_directory'], phenotype_name_post_clean)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if samples_cluster_dict['method'] == 'cc_net_nmf':\n",
    "    sc_tbx.run_cc_net_nmf(samples_cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
